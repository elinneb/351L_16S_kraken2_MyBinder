###############################################
########## Add sequencing data to input files folder
###############################################

# Drag and drop (or upload) the zipped folder "fastq_files" downloaded from CC into the file explorer on the left
# WAIT for the upload bar at the bottom to finish
# Click on "Terminal" icon in the right panel. Window with "[/home/jovyan]$" in yellow should pop up.

## Begin running code in the terminal (paste uncommented lines into terminal and hit enter):

# Unzip the folder you added to the MyBinder and remove hidden MacOSX folders
unzip fastq_files && rm -r __MACOSX

# You should have a new folder "fastq_files", that has 1) all the sequence data, 2) a file with Illumina adapater sequences, and 3) an empty "trimmed_paired" folder in it.



###############################################
########## Run a quality check on the raw reads
###############################################

# Bring the terminal into the folder with the fastq files
cd ~/fastq_files

# Run a quality control check on ALL the raw fastq files in the folder "fastq_files"
fastqc *.fastq.gz

# Run multiqc to get a single summary of the fasted outputs in one place
multiqc .


# My Binder isn't able to visualize multiqc data, so you need to download it to see
# Right click on the "multiqc_report.html" output and download
# Click to open in downloads and it should open in browser



###############################################
########## Trim and filter the raw reads to output trimmed and filtered sequencing reads
###############################################

# set your sample names that you loaded
samps=('01_07' '01_08' '02_07' '02_08' '03_07' '03_08' '04_07' '04_08' '05_07' '05_08' '07_07' '07_08' '08_07' '08_08')

## Trim/filter the raw fastq files, remove adapter sequences, and output paired and unpaired reads separately
# Highlight ALL SIX of the below lines at once (from "for" through "done"), copy, and paste into terminal

for i in "${samps[@]}"; do 
    trimmomatic PE "$i"_R1.fastq.gz "$i"_R2.fastq.gz \
        trimmed_paired/"$i"_R1_paired.fastq.gz "$i"_R1_unpaired.fastq.gz \
        trimmed_paired/"$i"_R2_paired.fastq.gz "$i"_R2_unpaired.fastq.gz \
        ILLUMINACLIP:AdapterSeqs-PE.fa:2:30:10 SLIDINGWINDOW:4:15 MINLEN:36 HEADCROP:19
done


###############################################
########## Run a quality check on the trimmed, paired reads
###############################################

## Bring the terminal into the folder with the trimmed, paired fastq files
cd trimmed_paired

## Re-run a quality control check on ALL the PAIRED, FILTERED fastq files
fastqc *_paired.fastq.gz

# run multiqc to get a single summary of the fasted outputs in one place
multiqc .


# My Binder isn't able to visualize multiqc data, so you need to download it to see
# Right click on the "multiqc_report.html" output and download
# Click to open in downloads and it should open in browser


###############################################
########## Use Kraken2 to classify trimmed, paired sequencing reads against a 16S sequence database
########## To get taxonomy of classified reads
###############################################

## Bring the terminal into the home folder
cd ~


## Perform taxonomic classification of filtered reads against the 16S rRNA database, using the classifier program "Kraken2"
# Highlight ALL SIX of the below lines at once (from "for" through "done"), copy, and paste into terminal

for i in "${samps[@]}"; do 
    kraken2 --paired --db SILVA_DB \
        --report kraken_outputs/"$i"_kraken2_report.txt \
        fastq_files/trimmed_paired/"$i"_R1_paired.fastq.gz \
        fastq_files/trimmed_paired/"$i"_R2_paired.fastq.gz
done


###############################################
########## Wrangle the data to get it in the format we want
###############################################

## Merge Kraken2 output files into a single "biom" table, by ORDER

kraken-biom kraken_outputs/*_kraken2_report.txt --max O --min O -o merged_16S_kraken_order.biom



## Biom tables are hard to read, so convert biom table to "OTU" table, which has abundances of each consensus lineage

biom convert -i merged_16S_kraken_order.biom -o merged_16S_kraken_order_table.txt --to-tsv --header-key taxonomy --output-metadata-id "taxonomy"



## This is super ugly code, but it basically cleans up the output to you don't have to do the work in Excel later
## Steps: Delete first column and row, move last column to first column, deletes row that has Cyanobacteria (Choloroplasts) and Arthropods in it, orders columns in decreasing order by first sample

awk -F'\t' 'NR>1 {for (i=2; i<=NF; i++) printf "%s%s", (i>2 ? "\t" : ""), $i; print ""}' merged_16S_kraken_order_table.txt | awk 'BEGIN{FS=OFS="\t"} {print $NF, substr($0, 1, length($0)-length($NF)-1)}' | awk '!/^k__Bacteria; p__Cyanobacteria; c__Cyanobacteriia; o__Chloroplast;/' | awk '!/^k__Holozoa; p__Arthropoda;/' > temp.txt && { head -n 1 temp.txt; tail -n +2 temp.txt | sort -t$'\t' -k2,2nr; } > merged_16S_kraken_order_clean.txt


## Right-click and Download the file "merged_16S_kraken_order_clean.txt"
## Open it on your computer in Excel to create a stacked barplot of the data





###############################################
########## OPTIONAL: If you want to infer functional information from the data!
###############################################

## Merge Kraken2 output files into a single "biom" table, incorporating all taxonomic levels (not just to Order)

kraken-biom kraken_outputs/*_kraken2_report.txt -o merged_16S_kraken_ALL.biom


## Biom tables are hard to read, so convert biom table to "OTU" table, which has abundances of each consensus lineage

biom convert -i merged_16S_kraken_ALL.biom -o merged_16S_kraken_ALL_table.txt --to-tsv --header-key taxonomy --output-metadata-id "taxonomy"



## This is super ugly code, but it basically cleans up the output to you don't have to do the work in Excel later
## Steps: Delete first column and row, move last column to first column, deletes row that has Cyanobacteria (Choloroplasts) and Arthropods in it, orders columns in decreasing order by first sample

awk -F'\t' 'NR>1 {for (i=2; i<=NF; i++) printf "%s%s", (i>2 ? "\t" : ""), $i; print ""}' merged_16S_kraken_ALL_table.txt | awk 'BEGIN{FS=OFS="\t"} {print $NF, substr($0, 1, length($0)-length($NF)-1)}' | awk '!/^k__Bacteria; p__Cyanobacteria; c__Cyanobacteriia; o__Chloroplast;/' | awk '!/^k__Holozoa; p__Arthropoda;/' > temp.txt && { head -n 1 temp.txt; tail -n +2 temp.txt | sort -t$'\t' -k2,2nr; } > merged_16S_kraken_ALL_clean.tsv



## Make the FAPROTAX python script executable
chmod +x FAPROTAX_1.2.7/collapse_table.py


## Run FAPROTAX to infer functional groups from the taxonomic output
FAPROTAX_1.2.7/collapse_table.py -i merged_16S_kraken_ALL_clean.tsv -o merged_16S_func_table.tsv -g FAPROTAX_1.2.7/FAPROTAX.txt -d "taxonomy" -c "#" -v


## Right-click and Download the file "merged_16S_func_table.tsv"
## Open it on your computer in Excel to analyze and visualize inferred functional data
## REMEMBER these are still absolute counts - need to be converted to relative abundance

